# Disaster Response Pipeline Project
This repository contains my project submission to the Disaster Response Pipeline project of the Udacity Data Scientist course.

## Project Summary

This project implements a machine learning pipeline for message classification. It includes a web app where an emergency worker can input a new message and get classification results in 36 categories. The web app also displays several visualizations of the data.

The code is basically structured into three parts that build on each other:

1. A module that cleans raw input data, joins categories and messages and re-encodes the raw data into binary features. The results are stored in an [SQLite](https://sqlite.org) database.

1. A module that takes the cleaned data, initializes a machine learning pipeline that tokenizes and lemmatizes input text and trains a random forest based multi-classifier with 36 target classes. The best parameters for the classifier are identified using Gridsearch, and the best performing model is stored.  

1. A module that locally deploys a [Flask](https://flask.palletsprojects.com) app that plots an overview of the data and offers an input field to classify new messages using the model trained in the previous step.

## Repository Structure
The repository is structured as follows:

```bash
ds-disaster-response-pipeline
├── app
│   ├── run.py                        # Module to run flask app and host HTML page.
│   └── templates
│       ├── go.html                   # HTML template for categorization results table.
│       └── master.html               # HTML template for main page.            
├── data
│   ├── disaster_categories.csv       # Raw input data: categories.
│   ├── disaster_messages.csv         # Raw input data: messages.
│   └── process_data.py               # Module to clean data and re-encode features.
├── docs                              
│   ├── make.bat                      # Windows batch file for Sphinx documentation generation.
│   ├── Makefile                      # Makefile for Sphinx documentation generation.
│   ├── source
│   │   ├── conf.py                   # Sphinx configuration.
│   │   └── index.rst                 # Template for main documentation page.
│   └── build                         # Target directory for Sphinx documentation generation.
│       └── README.md                 # Readme file. 
├── models
│   └── train_classifier.py           # Module that trains and saves message classifier.
├── .gitignore                        # Gitignore file. 
├── requirements.txt                  # List of imported Python packages.
├── requirements_full.txt             # List of full environment Python packages.
└── README.md                         # This file.
```

## Usage

### Prerequisites
This project was built using Python 3.6.3 and imports the following packages:

`Flask` version 0.12.5  
`nltk` version 3.2.5  
`pandas` version 0.23.3  
`plotly` version 2.0.15  
`scikit-learn` version 0.19.1 
`SQLAlchemy` version 1.2.19  

The following command will install these packages according to the configuration file `requirements.txt`.

```
$ pip install -r requirements.txt
```

Note: the file `requirements.txt` was generated using `pipreqs` and only has information on the imported packages, not their dependencies. The full list of packages (as generated by `pip3 freeze`) is listed in `requirements_full.txt`.

### Execution

1. Run the following commands in the project's root directory to set up your database and model.

    - To run ETL pipeline that cleans data and stores in database
   ```
   $ python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db
   ```
    - To run ML pipeline that trains classifier and saves
   ```
   $ python models/train_classifier.py data/DisasterResponse.db models/classifier.pkl
   ```

1. Run the following command in the app's directory to run your web app.
   ```
   $ python run.py
   ```

1. Go to http://0.0.0.0:3001/

## Documentation

The documentation of this project is built using the Python Documentation Generator [Sphinx](https://www.sphinx-doc.org/). The generated documentation is not part of this repository, it needs to be built. To do so, execute the following commands:

1. Install Sphinx (only once):
   ```
   $ pip install -U sphinx
   ```

1. Generate documentation:
   ```
   $ sphinx-build -b html docs/source/ docs/build/html
   ```
   or
   ```
   $ cd docs/source
   $ make html
   ```

Other targets than HTML are also possible, refer to the [`sphinx-build` documentation](https://www.sphinx-doc.org/en/master/man/sphinx-build.html).
